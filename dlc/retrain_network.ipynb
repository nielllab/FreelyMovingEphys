{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut \n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import trange, tqdm\n",
    "from tkinter import filedialog\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Initial Videos for Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = r'T:\\deeplabcut_projects\\BinocularOpto-Elliott-2021-08-12\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(basepath, path):\n",
    "    if path in basepath.as_posix():\n",
    "        return basepath\n",
    "    elif not (basepath / path).exists():\n",
    "        (basepath / path).mkdir(exist_ok=True,parents=True)\n",
    "        print('Added Directory:'+ (basepath / path).as_posix())\n",
    "        return (basepath / path)\n",
    "    else:\n",
    "        return (basepath / path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_paths = Path(r'T:\\\\BinocOptoPreyCapture\\\\')\n",
    "new_vids = list(vid_paths.rglob('*.avi'))\n",
    "new_vids = [vid.as_posix() for vid in new_vids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anis = np.unique([vid.split('/')[3] for vid in new_vids])\n",
    "dates = np.unique([vid.split('/')[2] for vid in new_vids])\n",
    "trials = np.unique([vid.split('/')[4] for vid in new_vids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = []\n",
    "for date in dates:\n",
    "    for ani in anis:\n",
    "        trial = np.random.randint(1,len(trials)+1)\n",
    "        vvid = list((vid_paths / date / ani / str(trial)).glob('*.avi'))\n",
    "        if vvid != []:\n",
    "            vids.append(vvid[0])\n",
    "            vids.append(vvid[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vids = [vid.as_posix() for vid in vids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T:/BinocOptoPreyCapture/080921/PV154pink/5/080921_PV154pink_n_Wno_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PV154pink/5/080921_PV154pink_n_Wno_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha2black/1/080921_PVCha2black_n_Wno_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha2black/1/080921_PVCha2black_n_Wno_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha2green/3/080921_PVCha2green_n_Wno_3_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha2green/3/080921_PVCha2green_n_Wno_3_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha3black/4/080921_PVCha3black_n_Wno_4_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha3black/4/080921_PVCha3black_n_Wno_4_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha3green/5/080921_PVCha3green_n_Wno_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha3green/5/080921_PVCha3green_n_Wno_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha3white/3/080921_PVCha3white_n_Wno_3_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha3white/3/080921_PVCha3white_n_Wno_3_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha5Ablack/3/080921_PVCha5Ablack_n_Wno_3_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha5Ablack/3/080921_PVCha5Ablack_n_Wno_3_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha5Agreen/1/080921_PVCha5Agreen_n_Wno_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha5Agreen/1/080921_PVCha5Agreen_n_Wno_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha5Apink/5/080921_PVCha5Apink_n_Wno_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha5Apink/5/080921_PVCha5Apink_n_Wno_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PV154black/2/081021_PV154black_n_Wsb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PV154black/2/081021_PV154black_n_Wsb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PV154pink/2/081021_PV154pink_n_Wsb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PV154pink/2/081021_PV154pink_n_Wsb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha2black/3/081021_PVCha2black_n_Wsb_3_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha2black/3/081021_PVCha2black_n_Wsb_3_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha2green/5/081021_PVCha2green_n_Wsb_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha2green/5/081021_PVCha2green_n_Wsb_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3black/2/081021_PVCha3black_n_Wsb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3black/2/081021_PVCha3black_n_Wsb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3green/1/081021_PVCha3green_n_Wsb_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3green/1/081021_PVCha3green_n_Wsb_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3white/1/081021_PVCha3white_n_Wsb_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3white/1/081021_PVCha3white_n_Wsb_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha5Ablack/4/081021_PVCha5Ablack_n_Wsb_4_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha5Ablack/4/081021_PVCha5Ablack_n_Wsb_4_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha5Agreen/3/081021_PVCha5Agreen_n_Wsb_3_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha5Agreen/3/081021_PVCha5Agreen_n_Wsb_3_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha5Apink/2/081021_PVCha5Apink_n_Wsb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha5Apink/2/081021_PVCha5Apink_n_Wsb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PV154black/4/081121_PV154black_n_Wsw_4_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PV154black/4/081121_PV154black_n_Wsw_4_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PV154pink/1/081121_PV154pink_n_Wsw_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PV154pink/1/081121_PV154pink_n_Wsw_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2black/1/081121_PVCha2black_n_Wsw_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2black/1/081121_PVCha2black_n_Wsw_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2green/3/081121_PVCha2green_n_Wsw_3_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2green/3/081121_PVCha2green_n_Wsw_3_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha3black/3/081121_PVCha3black_n_Wsw_3_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha3black/3/081121_PVCha3black_n_Wsw_3_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha3green/1/081121_PVCha3green_n_Wsw_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha3green/1/081121_PVCha3green_n_Wsw_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha3white/1/081121_PVCha3white_n_Wsw_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha3white/1/081121_PVCha3white_n_Wsw_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha5Ablack/5/081121_PVCha5Ablack_n_Wsw_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha5Ablack/5/081121_PVCha5Ablack_n_Wsw_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha5Agreen/2/081121_PVCha5Agreen_n_Wsw_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha5Agreen/2/081121_PVCha5Agreen_n_Wsw_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha5Apink/1/081121_PVCha5Apink_n_Wsw_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha5Apink/1/081121_PVCha5Apink_n_Wsw_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PV154black/2/081221_PV154black_n_Wlb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PV154black/2/081221_PV154black_n_Wlb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PV154pink/1/081221_PV154pink_n_Wlb_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PV154pink/1/081221_PV154pink_n_Wlb_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha2black/2/081221_PVCha2black_n_Wlb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha2black/2/081221_PVCha2black_n_Wlb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha2green/5/081221_PVCha2green_n_Wlb_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha2green/5/081221_PVCha2green_n_Wlb_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3black/2/081221_PVCha3black_n_Wlb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3black/2/081221_PVCha3black_n_Wlb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3green/1/081221_PVCha3green_n_Wlb_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3green/1/081221_PVCha3green_n_Wlb_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3white/5/081221_PVCha3white_n_Wlb_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3white/5/081221_PVCha3white_n_Wlb_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha5Ablack/2/081221_PVCha5Ablack_n_Wlb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha5Ablack/2/081221_PVCha5Ablack_n_Wlb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha5Agreen/1/081221_PVCha5Agreen_n_Wlb_1_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha5Agreen/1/081221_PVCha5Agreen_n_Wlb_1_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha5Apink/2/081221_PVCha5Apink_n_Wlb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha5Apink/2/081221_PVCha5Apink_n_Wlb_2_TOP2.avi']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['PV154black', 'PV154pink', 'PVCha2black', 'PVCha2green',\n",
       "        'PVCha3black', 'PVCha3green', 'PVCha3white', 'PVCha5Ablack',\n",
       "        'PVCha5Agreen', 'PVCha5Apink'], dtype='<U12'),\n",
       " array(['080921', '081021', '081121', '081221'], dtype='<U6'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anis, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('T:/BinocOptoPreyCapture/081221/PVCha3green/2/081221_PVCha3green_n_Wlb_2_TOP1.avi'),\n",
       " WindowsPath('T:/BinocOptoPreyCapture/081221/PVCha3green/2/081221_PVCha3green_n_Wlb_2_TOP2.avi')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = '081221'\n",
    "ani = 'PVCha3green'\n",
    "trial = 2\n",
    "vvid = list((vid_paths / date / ani / str(trial)).glob('*.avi'))\n",
    "vvid\n",
    "# new_vids2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vids2 = ['T:/BinocOptoPreyCapture/080921/PVCha2black/4/080921_PVCha2black_n_Wno_4_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/080921/PVCha2black/4/080921_PVCha2black_n_Wno_4_TOP2.avi',\n",
    " 'T:/BinocOptoPreyCapture/080921/PVChA2green/2/080921_PVCha2green_n_Wno_2_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/080921/PVChA2green/2/080921_PVCha2green_n_Wno_2_TOP2.avi',\n",
    " 'T:/BinocOptoPreyCapture/081021/PVCha3white/2/081021_PVCha3white_n_Wsb_2_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/081021/PVCha3white/2/081021_PVCha3white_n_Wsb_2_TOP2.avi',\n",
    " 'T:/BinocOptoPreyCapture/081021/PVCha3green/2/081021_PVCha3green_n_Wsb_2_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/081021/PVCha3green/2/081021_PVCha3green_n_Wsb_2_TOP2.avi',\n",
    " 'T:/BinocOptoPreyCapture/081121/PVCha2black/2/081121_PVCha2black_n_Wsw_2_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/081121/PVCha2black/2/081121_PVCha2black_n_Wsw_2_TOP2.avi',\n",
    " 'T:/BinocOptoPreyCapture/081121/PVCha2black/5/081121_PVCha2black_n_Wsw_5_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/081121/PVCha2black/5/081121_PVCha2black_n_Wsw_5_TOP2.avi',\n",
    " 'T:/BinocOptoPreyCapture/081221/PVCha3white/2/081221_PVCha3white_n_Wlb_2_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/081221/PVCha3white/2/081221_PVCha3white_n_Wlb_2_TOP2.avi',\n",
    " 'T:/BinocOptoPreyCapture/081221/PVCha3green/2/081221_PVCha3green_n_Wlb_2_TOP1.avi',\n",
    " 'T:/BinocOptoPreyCapture/081221/PVCha3green/2/081221_PVCha3green_n_Wlb_2_TOP2.avi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T:/BinocOptoPreyCapture/080921/PVCha2black/4/080921_PVCha2black_n_Wno_4_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVCha2black/4/080921_PVCha2black_n_Wno_4_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVChA2green/2/080921_PVCha2green_n_Wno_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/080921/PVChA2green/2/080921_PVCha2green_n_Wno_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3white/2/081021_PVCha3white_n_Wsb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3white/2/081021_PVCha3white_n_Wsb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3green/2/081021_PVCha3green_n_Wsb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081021/PVCha3green/2/081021_PVCha3green_n_Wsb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2black/2/081121_PVCha2black_n_Wsw_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2black/2/081121_PVCha2black_n_Wsw_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2black/5/081121_PVCha2black_n_Wsw_5_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081121/PVCha2black/5/081121_PVCha2black_n_Wsw_5_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3white/2/081221_PVCha3white_n_Wlb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3white/2/081221_PVCha3white_n_Wlb_2_TOP2.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3green/2/081221_PVCha3green_n_Wlb_2_TOP1.avi',\n",
       " 'T:/BinocOptoPreyCapture/081221/PVCha3green/2/081221_PVCha3green_n_Wlb_2_TOP2.avi']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vids2.append(vvid[0].as_posix())\n",
    "new_vids2.append(vvid[1].as_posix())\n",
    "new_vids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.add_new_videos(config_path,new_vids2,copy_videos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Random Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations, permutations\n",
    "import itertools\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "legos = ['no', 'lb', 'sb', 'sw']\n",
    "# legos = [1,2,3,4]\n",
    "wallpapers = ['W','H','L']\n",
    "# comb = combinations(wallpapers,legos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb = list(itertools.product(wallpapers,legos))\n",
    "# comb = [comb[n][0]+comb[n][1] for n in range(len(comb))]\n",
    "comb = ['Lno', 'Hno', 'Wno', 'Wsb', 'Wsw', 'Wlb', 'Lsb', 'Hsb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "set1=np.random.choice(comb,replace=False,size=len(comb))\n",
    "set2=np.random.choice(comb,replace=False,size=len(comb))\n",
    "set3=np.random.choice(comb,replace=False,size=len(comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list =pd.Series(pd.bdate_range(\"08/16/2021\", freq=\"B\", periods=len(sets)))\n",
    "sets = np.concatenate((set1,set2,set3),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = (np.array([sorted(np.random.choice(np.arange(1,6),replace=False,size=3)) for n in range(len(sets))])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'dates':date_list,\n",
    "                   'condition': sets,\n",
    "                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "anis = ['PVCha2black', 'PVCha2green', 'PVCha3white', 'PVCha3black', 'PVCha3green', 'PVCha5Agreen', 'PVCha5Apink', 'PVCha5Ablack', 'PV154pink', 'PV154black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ani in anis:\n",
    "    df[ani] = (np.array([sorted(np.random.choice(np.arange(1,6),replace=False,size=3)) for n in range(len(sets))])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2021-08-16\n",
       "1    2021-08-17\n",
       "2    2021-08-18\n",
       "3    2021-08-19\n",
       "4    2021-08-20\n",
       "5    2021-08-23\n",
       "6    2021-08-24\n",
       "7    2021-08-25\n",
       "8    2021-08-26\n",
       "9    2021-08-27\n",
       "10   2021-08-30\n",
       "11   2021-08-31\n",
       "12   2021-09-01\n",
       "13   2021-09-02\n",
       "14   2021-09-03\n",
       "15   2021-09-06\n",
       "16   2021-09-07\n",
       "17   2021-09-08\n",
       "18   2021-09-09\n",
       "19   2021-09-10\n",
       "20   2021-09-13\n",
       "21   2021-09-14\n",
       "22   2021-09-15\n",
       "23   2021-09-16\n",
       "24   2021-09-17\n",
       "25   2021-09-20\n",
       "26   2021-09-21\n",
       "27   2021-09-22\n",
       "28   2021-09-23\n",
       "29   2021-09-24\n",
       "30   2021-09-27\n",
       "31   2021-09-28\n",
       "32   2021-09-29\n",
       "33   2021-09-30\n",
       "34   2021-10-01\n",
       "35   2021-10-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting for now!\n"
     ]
    }
   ],
   "source": [
    "# deeplabcut.extract_frames(config_path, mode='auto', algo='kmeans', userfeedback=False, crop=False)\n",
    "deeplabcut.extract_frames(config_path, mode='manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 1.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([393, 130, 285, 355, 466, 230, 243, 448, 465,  99, 103,   9, 156,\n",
       "           41,  43, 111,  26, 217,   2,  71,  50,  63,  39,   3, 205, 181,\n",
       "          220,  75, 284, 174, 138, 312, 302,  54, 415,  33, 261, 265, 420,\n",
       "           12, 216, 327, 365, 425,  38, 215, 101, 423, 391,  36, 342,  11,\n",
       "          319,  72, 187, 437, 125, 213, 124, 296, 264, 412, 289, 383, 286,\n",
       "           94, 314, 251, 331, 102, 340, 443, 120, 235, 395, 359, 307, 385,\n",
       "           37, 434, 110, 247, 267, 115,  96, 397, 129, 281, 155, 168, 132,\n",
       "           44, 148, 108, 227,  52, 147, 382, 316, 144, 317, 109, 293, 350,\n",
       "           46, 410, 182, 456,  88,  22, 160,  97, 297, 273, 190, 299,  51,\n",
       "           32, 458, 142, 199, 237,  31, 245,  61, 258, 320, 169, 136, 400,\n",
       "          196, 300, 394, 330, 141, 310, 145,  93,  45, 294, 411, 367, 112,\n",
       "          234,  86, 390, 380, 226, 189, 204,  83,  55, 435, 360, 338,  60,\n",
       "           21, 263, 346, 462, 287, 210,  19, 255, 107,  65, 177,  80,  53,\n",
       "          105, 228, 222, 438, 274, 133, 424, 256, 369, 389,  23,  30, 341,\n",
       "          238, 326, 445,  62,   0, 361, 270, 269, 233, 363, 257, 280, 388,\n",
       "          332, 371, 417, 335, 427, 368, 278, 116, 329, 414, 165, 336, 218,\n",
       "           20, 421, 200, 460, 348, 455, 175, 436, 313, 444, 240, 173,  82,\n",
       "          318, 209, 188, 439, 262, 323,  85, 248,  34, 352, 433, 146, 292,\n",
       "          399, 253, 157, 428, 469, 304, 149, 207, 463,  15, 459, 193,  77,\n",
       "          266,  59, 236, 231, 195,  84,  89, 378, 404,  17, 396, 322, 334,\n",
       "          249, 244, 239, 398, 449,  76, 321, 126, 206, 203, 246,  95, 211,\n",
       "          384, 162, 143, 279, 379, 452,   1, 178,  69, 191, 315, 345, 451,\n",
       "          392, 440, 373, 298, 151, 453, 468,   6, 260, 164, 372, 290, 259,\n",
       "          403, 409,  64, 198,  28,  49,   4, 422,  57, 339, 362, 275, 432,\n",
       "          139, 471, 325, 208, 241, 184, 119, 357, 351,  58, 214, 276, 172,\n",
       "          386, 212,  90, 186, 470, 402, 134, 202, 472,  42, 407, 135,  29,\n",
       "          283, 467, 309, 288, 229,  56, 303, 225, 305,  98, 121, 163, 221,\n",
       "          408, 171, 356, 183,  16, 252, 464,  74, 311, 405, 254, 308,  87,\n",
       "          250, 282, 343,  79, 152, 197,  24, 333, 418,  14, 416, 291, 268,\n",
       "          406,  35, 370, 170, 113, 349, 123, 153, 401, 167, 104, 306, 358,\n",
       "           10, 180, 127, 219, 272, 154,  48, 419,  92, 158, 429, 446, 100,\n",
       "           73, 224,  67, 176, 166, 413, 375,  25, 447,  27, 337, 430, 192,\n",
       "          387, 441,  13, 185, 376, 159,   8, 128, 194, 353, 106, 354, 328,\n",
       "          117,   7, 374, 179,  68, 131, 114, 461, 122, 271, 140,  70, 364,\n",
       "          301, 431,  66, 232, 426, 277,   5]),\n",
       "   array([344, 377, 295, 242, 137, 454,  91,  40, 223,  78,  18, 150,  47,\n",
       "          324, 118, 442, 381, 457, 366, 161, 201, 450,  81, 347])))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path, augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pose_config.yaml\n",
    "cfg = deeplabcut.auxiliaryfunctions.read_config(config_path)\n",
    "# Add imageaug to pose_config.yaml \n",
    "trainposeconfigfile,testposeconfigfile,snapshotfolder=deeplabcut.return_train_network_path(config_path)\n",
    "cfg_dlc=deeplabcut.auxiliaryfunctions.read_plainconfig(trainposeconfigfile)\n",
    "cfg_dlc['scale_jitter_lo']= 0.5\n",
    "cfg_dlc['scale_jitter_up']=1.5\n",
    "cfg_dlc['augmentationprobability']=.5\n",
    "cfg_dlc['batch_size']=6 #pick that as large as your GPU can handle it\n",
    "cfg_dlc['elastic_transform']=True\n",
    "cfg_dlc['rotation']=180\n",
    "cfg_dlc['covering']=True\n",
    "cfg_dlc['motion_blur'] = True\n",
    "cfg_dlc['optimizer'] =\"adam\"\n",
    "cfg_dlc['dataset_type']='imgaug' # 'imagaug'multi-animal-\n",
    "cfg_dlc['multi_step']=[[1e-4, 7500], [5.0e-5, 12000], [1e-5, 50000]]\n",
    "cfg_dlc['init_weights'] = 'C:/Users/Niell Lab/Documents/deeplabcut_projects/EphysEyeCams3-dylan-2021-02-02/dlc-models/iteration-0/EphysEyeCams3Feb2-trainset95shuffle1/train/snapshot-800000'\n",
    "deeplabcut.auxiliaryfunctions.write_plainconfig(trainposeconfigfile,cfg_dlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function evaluate_network in module deeplabcut.pose_estimation_tensorflow.core.evaluate:\n",
      "\n",
      "evaluate_network(config, Shuffles=[1], trainingsetindex=0, plotting=None, show_errors=True, comparisonbodyparts='all', gputouse=None, rescale=False, modelprefix='')\n",
      "    Evaluates the network based on the saved models at different stages of the training network.\n",
      "    \n",
      "    The evaluation results are stored in the .h5 and .csv file under the subdirectory 'evaluation_results'.\n",
      "    Change the snapshotindex parameter in the config file to 'all' in order to evaluate all the saved models.\n",
      "    Parameters\n",
      "    ----------\n",
      "    config : string\n",
      "        Full path of the config.yaml file as a string.\n",
      "    \n",
      "    Shuffles: list, optional\n",
      "        List of integers specifying the shuffle indices of the training dataset. The default is [1]\n",
      "    \n",
      "    trainingsetindex: int, optional\n",
      "        Integer specifying which TrainingsetFraction to use. By default the first (note that TrainingFraction is a list in config.yaml). This\n",
      "        variable can also be set to \"all\".\n",
      "    \n",
      "    plotting: bool, optional\n",
      "        Plots the predictions on the train and test images. The default is ``False``; if provided it must be either ``True`` or ``False``\n",
      "    \n",
      "    show_errors: bool, optional\n",
      "        Display train and test errors. The default is `True``\n",
      "    \n",
      "    comparisonbodyparts: list of bodyparts, Default is \"all\".\n",
      "        The average error will be computed for those body parts only (Has to be a subset of the body parts).\n",
      "    \n",
      "    gputouse: int, optional. Natural number indicating the number of your GPU (see number in nvidia-smi). If you do not have a GPU put None.\n",
      "        See: https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries\n",
      "    \n",
      "    rescale: bool, default False\n",
      "        Evaluate the model at the 'global_scale' variable (as set in the test/pose_config.yaml file for a particular project). I.e. every\n",
      "        image will be resized according to that scale and prediction will be compared to the resized ground truth. The error will be reported\n",
      "        in pixels at rescaled to the *original* size. I.e. For a [200,200] pixel image evaluated at global_scale=.5, the predictions are calculated\n",
      "        on [100,100] pixel images, compared to 1/2*ground truth and this error is then multiplied by 2!. The evaluation images are also shown for the\n",
      "        original size!\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    If you do not want to plot\n",
      "    >>> deeplabcut.evaluate_network('/analysis/project/reaching-task/config.yaml', Shuffles=[1])\n",
      "    --------\n",
      "    If you want to plot\n",
      "    >>> deeplabcut.evaluate_network('/analysis/project/reaching-task/config.yaml',Shuffles=[1],True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(deeplabcut.evaluate_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['pt1',\n",
      "                      'pt2',\n",
      "                      'pt3',\n",
      "                      'pt4',\n",
      "                      'pt5',\n",
      "                      'pt6',\n",
      "                      'pt7',\n",
      "                      'pt8',\n",
      "                      'tear',\n",
      "                      'outer'],\n",
      " 'augmentationprobability': 0.5,\n",
      " 'batch_size': 6,\n",
      " 'covering': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_EphysEyeCams3Feb2\\\\EphysEyeCams3_dylan95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'elastic_transform': True,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:/Users/Niell '\n",
      "                 'Lab/Documents/deeplabcut_projects/EphysEyeCams3-dylan-2021-02-02/dlc-models/iteration-0/EphysEyeCams3Feb2-trainset95shuffle1/train/snapshot-800000',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_EphysEyeCams3Feb2\\\\Documentation_data-EphysEyeCams3_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'motion_blur': True,\n",
      " 'multi_step': [[0.0001, 7500], ['5e-05', 12000], ['1e-05', 50000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'adam',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Niell '\n",
      "                 'Lab\\\\Documents\\\\deeplabcut_projects\\\\EphysEyeCams3-dylan-2021-02-02',\n",
      " 'regularize': False,\n",
      " 'rotation': 180,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.5,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Niell '\n",
      "                    'Lab\\\\Documents\\\\deeplabcut_projects\\\\EphysEyeCams3-dylan-2021-02-02\\\\dlc-models\\\\iteration-1\\\\EphysEyeCams3Feb2-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 6\n",
      "Initializing ResNet\n",
      "Loading already trained DLC with backbone: resnet_50\n",
      "Max_iters overwritten as 50000\n",
      "Display_iters overwritten as 500\n",
      "Save_iters overwritten as 10000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\Niell Lab\\\\Documents\\\\deeplabcut_projects\\\\EphysEyeCams3-dylan-2021-02-02\\\\dlc-models\\\\iteration-1\\\\EphysEyeCams3Feb2-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'adam', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 6, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]], 'all_joints_names': ['pt1', 'pt2', 'pt3', 'pt4', 'pt5', 'pt6', 'pt7', 'pt8', 'tear', 'outer'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_EphysEyeCams3Feb2\\\\EphysEyeCams3_dylan95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:/Users/Niell Lab/Documents/deeplabcut_projects/EphysEyeCams3-dylan-2021-02-02/dlc-models/iteration-0/EphysEyeCams3Feb2-trainset95shuffle1/train/snapshot-800000', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_EphysEyeCams3Feb2\\\\Documentation_data-EphysEyeCams3_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.0001, 7500], ['5e-05', 12000], ['1e-05', 50000]], 'net_type': 'resnet_50', 'num_joints': 10, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\Niell Lab\\\\Documents\\\\deeplabcut_projects\\\\EphysEyeCams3-dylan-2021-02-02', 'rotation': 180, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.5, 'augmentationprobability': 0.5, 'elastic_transform': True, 'covering': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 500 loss: 0.0078 lr: 0.0001\n",
      "iteration: 1000 loss: 0.0065 lr: 0.0001\n",
      "iteration: 1500 loss: 0.0060 lr: 0.0001\n",
      "iteration: 2000 loss: 0.0059 lr: 0.0001\n",
      "iteration: 2500 loss: 0.0057 lr: 0.0001\n",
      "iteration: 3000 loss: 0.0054 lr: 0.0001\n",
      "iteration: 3500 loss: 0.0055 lr: 0.0001\n",
      "iteration: 4000 loss: 0.0054 lr: 0.0001\n",
      "iteration: 4500 loss: 0.0051 lr: 0.0001\n",
      "iteration: 5000 loss: 0.0049 lr: 0.0001\n",
      "iteration: 5500 loss: 0.0052 lr: 0.0001\n",
      "iteration: 6000 loss: 0.0050 lr: 0.0001\n",
      "iteration: 6500 loss: 0.0050 lr: 0.0001\n",
      "iteration: 7000 loss: 0.0048 lr: 0.0001\n",
      "iteration: 7500 loss: 0.0050 lr: 0.0001\n",
      "iteration: 8000 loss: 0.0043 lr: 5e-05\n",
      "iteration: 8500 loss: 0.0040 lr: 5e-05\n",
      "iteration: 9000 loss: 0.0041 lr: 5e-05\n",
      "iteration: 9500 loss: 0.0040 lr: 5e-05\n",
      "iteration: 10000 loss: 0.0041 lr: 5e-05\n",
      "iteration: 10500 loss: 0.0041 lr: 5e-05\n",
      "iteration: 11000 loss: 0.0039 lr: 5e-05\n",
      "iteration: 11500 loss: 0.0041 lr: 5e-05\n",
      "iteration: 12000 loss: 0.0039 lr: 5e-05\n",
      "iteration: 12500 loss: 0.0035 lr: 1e-05\n",
      "iteration: 13000 loss: 0.0034 lr: 1e-05\n",
      "iteration: 13500 loss: 0.0034 lr: 1e-05\n",
      "iteration: 14000 loss: 0.0034 lr: 1e-05\n",
      "iteration: 14500 loss: 0.0034 lr: 1e-05\n",
      "iteration: 15000 loss: 0.0033 lr: 1e-05\n",
      "iteration: 15500 loss: 0.0033 lr: 1e-05\n",
      "iteration: 16000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 16500 loss: 0.0032 lr: 1e-05\n",
      "iteration: 17000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 17500 loss: 0.0033 lr: 1e-05\n",
      "iteration: 18000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 18500 loss: 0.0032 lr: 1e-05\n",
      "iteration: 19000 loss: 0.0033 lr: 1e-05\n",
      "iteration: 19500 loss: 0.0032 lr: 1e-05\n",
      "iteration: 20000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 20500 loss: 0.0032 lr: 1e-05\n",
      "iteration: 21000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 21500 loss: 0.0032 lr: 1e-05\n",
      "iteration: 22000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 22500 loss: 0.0032 lr: 1e-05\n",
      "iteration: 23000 loss: 0.0031 lr: 1e-05\n",
      "iteration: 23500 loss: 0.0031 lr: 1e-05\n",
      "iteration: 24000 loss: 0.0031 lr: 1e-05\n",
      "iteration: 24500 loss: 0.0031 lr: 1e-05\n",
      "iteration: 25000 loss: 0.0031 lr: 1e-05\n",
      "iteration: 25500 loss: 0.0032 lr: 1e-05\n",
      "iteration: 26000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 26500 loss: 0.0031 lr: 1e-05\n",
      "iteration: 27000 loss: 0.0032 lr: 1e-05\n",
      "iteration: 27500 loss: 0.0031 lr: 1e-05\n",
      "iteration: 28000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 28500 loss: 0.0031 lr: 1e-05\n",
      "iteration: 29000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 29500 loss: 0.0031 lr: 1e-05\n",
      "iteration: 30000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 30500 loss: 0.0031 lr: 1e-05\n",
      "iteration: 31000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 31500 loss: 0.0030 lr: 1e-05\n",
      "iteration: 32000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 32500 loss: 0.0030 lr: 1e-05\n",
      "iteration: 33000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 33500 loss: 0.0030 lr: 1e-05\n",
      "iteration: 34000 loss: 0.0031 lr: 1e-05\n",
      "iteration: 34500 loss: 0.0030 lr: 1e-05\n",
      "iteration: 35000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 35500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 36000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 36500 loss: 0.0030 lr: 1e-05\n",
      "iteration: 37000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 37500 loss: 0.0030 lr: 1e-05\n",
      "iteration: 38000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 38500 loss: 0.0030 lr: 1e-05\n",
      "iteration: 39000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 39500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 40000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 40500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 41000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 41500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 42000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 42500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 43000 loss: 0.0030 lr: 1e-05\n",
      "iteration: 43500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 44000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 44500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 45000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 45500 loss: 0.0028 lr: 1e-05\n",
      "iteration: 46000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 46500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 47000 loss: 0.0029 lr: 1e-05\n",
      "iteration: 47500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 48000 loss: 0.0028 lr: 1e-05\n",
      "iteration: 48500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 49000 loss: 0.0028 lr: 1e-05\n",
      "iteration: 49500 loss: 0.0029 lr: 1e-05\n",
      "iteration: 50000 loss: 0.0029 lr: 1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Niell Lab\\.conda\\envs\\DLC-GPU2\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Niell Lab\\.conda\\envs\\DLC-GPU2\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Niell Lab\\.conda\\envs\\DLC-GPU2\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\Niell Lab\\.conda\\envs\\DLC-GPU2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\Niell Lab\\.conda\\envs\\DLC-GPU2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1075, in _run\n",
      "    raise RuntimeError('Attempted to use a closed Session.')\n",
      "RuntimeError: Attempted to use a closed Session.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate Network\n",
    "deeplabcut.train_network(config_path, allow_growth=True, displayiters=500, maxiters=100000, saveiters=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['pt1',\n",
      "                      'pt2',\n",
      "                      'pt3',\n",
      "                      'pt4',\n",
      "                      'pt5',\n",
      "                      'pt6',\n",
      "                      'pt7',\n",
      "                      'pt8',\n",
      "                      'tear',\n",
      "                      'outer'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_EphysEyeCams3Feb2\\\\EphysEyeCams3_dylan95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Niell '\n",
      "                 'Lab\\\\.conda\\\\envs\\\\DLC-GPU2\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Niell '\n",
      "                    'Lab\\\\Documents\\\\deeplabcut_projects\\\\EphysEyeCams3-dylan-2021-02-02\\\\dlc-models\\\\iteration-1\\\\EphysEyeCams3Feb2-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niell Lab\\Documents\\deeplabcut_projects\\EphysEyeCams3-dylan-2021-02-02/evaluation-results/  already exists!\n",
      "Running  DLC_resnet50_EphysEyeCams3Feb2shuffle1_50000  with # of trainingiterations: 50000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409it [00:11, 35.57it/s]\n",
      "  0%|                                                                                          | 0/409 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-50000\n",
      "Results for 50000  training iterations: 95 1 train error: 2.27 pixels. Test error: 3.09  pixels.\n",
      "With pcutoff of 0.6  train error: 2.27 pixels. Test error: 3.09 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [01:19<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path, plotting=True, trainingsetindex='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DEEPLABCUT]",
   "language": "python",
   "name": "conda-env-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
